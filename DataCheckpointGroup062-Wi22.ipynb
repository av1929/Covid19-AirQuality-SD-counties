{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Asher Av\n",
    "- Quoc-Zuy  Do\n",
    "- Hector Gallo\n",
    "- Jeremy Nurding\n",
    "- Andres Villegas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a statistically significant relationship between COVID-19 cases and the levels of NO<sub>2</sub> in the atmosphere in San Diego county during the years 2020 and 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name:\n",
    "- Link to the dataset:\n",
    "- Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets.\n",
    "\n",
    "\n",
    "**Data Set Name: COVID-19 Data - US Counties from NYTimes**\n",
    "- Link to Dataset: https://github.com/nytimes/covid-19-data\n",
    "- Number of Obsevations: 2,170,941 \n",
    "- <ins>Description of Dataset:</ins> This dataset is collated from  data across the U.S. by the New York Times and draws from the official reportings about the cumulative number of cases and deaths reported in each county and state across the U.S since the start of the COVID-19 pandemic. This dataset contains 6 columns of  data: date, county, state, fips, cases and  deaths. The FIPS column  crefers to a FIPS code, a geographic identifier that determines the location of the county the data was pulled from and makes it easy to associate with other datasets\n",
    "\n",
    "**Data Set Name: Air Quality Across Countries in COVID-19**\n",
    "- Link to Dataset: https://www.kaggle.com/aestheteaman01/air-quality-across-countries-in-covid19/version/3?select=USA.csv\n",
    "- Number of Observations: 179,365\n",
    "- <ins>Description of Dataset:</ins> This dataset shows the collected information of the air quality from 2020-2021 across countries including Brazil, Canada, France, Italy, India, and USA and their respective cities. The parameters that they use to show the air quality for each of the cities are the following: Carbon Monoxide (CO), Dew (dew), Humidity (humidity), Nitrogen Dioxide (NO2), Ozone (O3), Particulate Matter 10 (pm10, Particulate Matter 2.5 (pm25), Pressure (pressure), Sulphur Dioxide (SO2), Temperature, Wind Gusts, and Wind Speed.\n",
    "\n",
    "**Data Set Name: Air Quality Statistics by County, 2020**\n",
    "- Link to Dataset: https://www.epa.gov/air-trends/air-quality-cities-and-counties \n",
    "- Number of Observations: 1,144\n",
    "- <ins>Description of Dataset:</ins> The data set “Air Quality Statistics by County, 2020” presents data of counties with highest levels of air pollutants across states in the United States.  This data set is organized alphabetically in rows by state, each county is assigned to its state accordingly and also arranged in alphabetical order.  There are a total of 1162 rows in this data set and out of the total of rows however 1144 rows contain observations of air pollutants for specific counties.  This dataset contains 13 columns from left to right as follows: State, County, County FIPS Code, 2010 population, CO, Pb, NO2 AM (ppb), NO2 hr (ppb), O3, PM10, PM2.5 Wtd AM, PM2.5 hr, and SO2.  These show the highest number of such pollutant in the given area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nytimes daily covid dataset\n",
    "covid_df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\n",
    "\n",
    "# EPA 2020 NO2 dataset\n",
    "epa2020_df = pd.read_csv('https://raw.githubusercontent.com/asherbav/covid_pollution_files/main/epa2020.csv')\n",
    "\n",
    "# EPA 2021 NO2 dataset \n",
    "epa2021_df = pd.read_csv('https://raw.githubusercontent.com/asherbav/covid_pollution_files/main/epa2021.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### COVID-19 Dataset Cleaning\n",
    "The first thing that we want to do is take a look at the original datasets to see what they look like. We first take a look at the COVID-19 Dataset entitled: \"COVID-19 Data - US Counties from NYTimes\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to check if there are any null-values that we might want to get rid of  using isnull().sum. We see that there are a bunch of null values inside of the death's columns and the FIPS column. \n",
    "We also want to check the types of the columns to make sure that they are in the format that is desired for instance it seems that the dates were properly  converted to datetime objects, however the FIPS columns are floats instead of integers as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid_df.isnull().sum())\n",
    "print('-----------------') \n",
    "covid_df.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We however, will not be needing the deaths column for our analysis so we can drop the column entirely. We may want to keep the fips data however as creating a heatmaps of COVID-19 distribution across regions will allow us to analyze which regions are the most heavily impacted by the virus. This requires that we remove the entries where there are null values using dropna() from Pandas. \n",
    "\n",
    "We also want to change the type of the FIPS codes to integers so they are in the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_df.drop(['deaths'], axis = 1)\n",
    "covid_df = covid_df.dropna()\n",
    "covid_df['fips'] = covid_df['fips'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are done cleaning the COVID-19 dataset. We run isnull() again to double check that all the NULL/NaN values have been removed from out dataset properly. We also display the dataset and can see that the FIPS codes are now integers  as expected.  At this point the COVID-19 dataset has been cleaned and is now in a state where it can be used in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid_df.isnull().sum())\n",
    "print('-----------------') \n",
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Kaggle Air Quality Data Set Cleaning\n",
    "We repeat the steps for the COVID dataset from above for the Kaggle dataset on Air Quality. We display the dataset to  get an idea of what it looks like, search for any NULL/NaN values, and then also check the types of all the objects to make sure if everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(kagaq_df.isnull().sum())\n",
    "print('-----------------') \n",
    "#print(kagaq_df.dtypes)\n",
    "print('-----------------') \n",
    "#print(kagaq_df['Country'].value_counts())\n",
    "#kagaq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis we can see that there are no null values, and that data types of each column is as expected for this dataset. This dataset has already clean and we don't have to do much from here. However, this dataset has an extraneous column and that is the \"Country\" column. This particular dataset only had dataset for the United States of America, therefore this column does not provide any additional useful information we can safely drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kagaq_df = kagaq_df.drop(['Country'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we redisplay the data set and confirm that the column was removed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kagaq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### EPA 2020 Air Quality Data Set Cleaning\n",
    "First we display the data set to get an idea of what we're looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at each column for their unique values, we noticed that we can safely drop the 'County Codes', 'County', 'State', 'STATE_CODE' 'CBSA', 'CBSA_CODE', 'AQS_PARAMETER_DESC', 'AQS_PARAMETER_CODE','UNITS', and 'Source' columns as there is only a single value representing the entire dataset. \n",
    "The description of the dataset is as follows: The county and its associated code is 'San Diego', the CBSA is 'San Diego-Carlsbad, CA', the air quality parameter we're looking at is 'NO<sub>2</sub>', the unit is in ppb or parts per billion, and the source is 'AQS'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique values from columns\n",
    " ---\n",
    " County codes all the same\n",
    "\n",
    " County all the same\n",
    "\n",
    " State all the same\n",
    "\n",
    " CBSA name all the same\n",
    "\n",
    " CBSA code all the same\n",
    "\n",
    " AQS_PARAMETER_DESC all the same\n",
    "\n",
    " AQS_PARAMETER_CODE all the same\n",
    " \n",
    "\n",
    " UNITS all the same in ppb(part per billion)\n",
    "\n",
    " Source all the same in AQS\n",
    "\n",
    " PERCENT_COMPLETE = [ 92., 100.,  83.,  88.,  75.,  79.,  96.]\n",
    "\n",
    " Site name = ['Chula Vista', 'Alpine', 'Camp Pendleton', 'Donovan',\n",
    "       #'Kearny Villa Rd.', 'San Diego -Rancho Carmel Drive',\n",
    "       #'El Cajon - Lexington Elementary School',\n",
    "       #'San Diego - Sherman Elementary School']\n",
    "\n",
    " DAILY_OBS_COUNT = [22, 24, 20, 21, 18, 19, 23]\n",
    "\n",
    " DAILY AQI VALUE = [17, 33, 34, 29, 38, 35, 28, 24, 30, 26, 21, 27, 36, 31, 25, 32, 15,\n",
    "       # 23, 40, 16, 13, 39,  8, 22, 11, 12, 18,  7, 19, 20, 10, 14,  6,  4,\n",
    "       # 9,  3,  5,  2, 41, 37, 42,  1, 53, 43, 55, 44, 45, 46, 47, 52, 48,\n",
    "       #49, 51, 50]\n",
    "\n",
    " Daily Max 1-hour NO2 Concentration = [18, 35, 36, 31, 40, 37, 30, 25, 32, 28, 22, 29, 38, 33, 26, 34, 16,\n",
    "       # 24, 42, 17, 14, 41, 27,  8, 23, 12, 13, 19,  7, 20, 21, 11, 15,  9,\n",
    "       # 6,  4, 10,  3,  5,  2, 43, 39, 45, 44,  1, 56, 46, 58, 47, 48, 49,\n",
    "       # 50, 55, 51, 52, 54, 53]\n",
    "\n",
    " POC = [1, 2]\n",
    "\n",
    " Site ID = [60730001, 60731006, 60731008, 60731014, 60731016, 60731017, 60731022, 60731026]\n",
    " \n",
    " Dates range from 1/01/2020 to 12/31/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df = epa2020_df.drop(['COUNTY'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['COUNTY_CODE'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['STATE'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['STATE_CODE'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['CBSA_NAME'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['CBSA_CODE'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['AQS_PARAMETER_DESC'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['AQS_PARAMETER_CODE'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['UNITS'], axis = 1)\n",
    "epa2020_df = epa2020_df.drop(['Source'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there's no null values in the dataset and so we do not have any rows to remove. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the 2021 dataset has a very similar situation and so we drop the same columns as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2021_df = epa2021_df.drop(['COUNTY'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['COUNTY_CODE'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['STATE'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['STATE_CODE'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['CBSA_NAME'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['CBSA_CODE'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['AQS_PARAMETER_DESC'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['AQS_PARAMETER_CODE'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['UNITS'], axis = 1)\n",
    "epa2021_df = epa2021_df.drop(['Source'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2021_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#new_header = epa_df.iloc[2] #grab the first row for the header\n",
    "#epa_df = epa_df[3:] #take the data less the header row\n",
    "#epa_df.columns = new_header #set the header row as the df header\n",
    "#epa_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
