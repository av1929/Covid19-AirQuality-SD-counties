{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Asher Av\n",
    "- Quoc-Zuy  Do\n",
    "- Hector Gallo\n",
    "- Jeremy Nurding\n",
    "- Andres Villegas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='research_question'></a>\n",
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a statistically significant relationship between COVID-19 cases and the levels of NO<sub>2</sub> in the atmosphere in San Diego county during the years 2020 and 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name:\n",
    "- Link to the dataset:\n",
    "- Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets.\n",
    "\n",
    "**Data Set Name: COVID-19 Data - US Counties from NYTimes**\n",
    "- Link to Dataset: https://github.com/nytimes/covid-19-data\n",
    "- Number of Obsevations: 2,170,941 \n",
    "- <ins>Description of Dataset:</ins> This dataset is collated from  data across the U.S. by the New York Times and draws from the official reportings about the cumulative number of cases and deaths reported in each county and state across the U.S since the start of the COVID-19 pandemic. This dataset contains 6 columns of  data: date, county, state, fips, cases and  deaths. The FIPS column  crefers to a FIPS code, a geographic identifier that determines the location of the county the data was pulled from and makes it easy to associate with other datasets\n",
    "\n",
    "**Data Set Name: EPA 2020 Air Quality**\n",
    "- Link to Dataset: https://www.epa.gov/outdoor-air-quality-data/download-daily-data \n",
    "- Number of Observations: 2,869\n",
    "- <ins>Description of Dataset:</ins> This dataset tool allows us to analyze data by selecting a specific air pollutant, year, county, and site.  This dataset has collected data for NO<sub>2</sub> concentration in the atmosphere in eight different sites in San Diego county for the year 2020.  For each site in San Diego county there is information for each day of the year and the concentration of NO<sub>2</sub> concentration for the given date.  This data set contains 20 columns of data: Date, Source, Site ID, POC, Daily Max 1-hour NO<sub>2</sub> concentration, Units, Daily AQI Value, Site Name, Site Name (number), Percent Complete, Aqs Parameter Code, AQS Parameter DESC, CBSA Code, CBSA Name, State Code, State,County Code, County, Site Latitude, and Site Longitude.  There are 2,870 rows in this data set 2,869 of them contain observations. \n",
    "\n",
    "**Data Set Name: EPA 2021 Air Quality**\n",
    "- Link to Dataset: https://www.epa.gov/outdoor-air-quality-data/download-daily-data \n",
    "- Number of Observations: 2,011\n",
    "- <ins>Description of Dataset:</ins> This dataset has collected data for the concentration of the NO<sub>2</sub> in the atmosphere in eight different sites in San Diego county for the year 2021.  For each site in San Diego county there is information for each day of the year and the concentration of NO<sub>2</sub> concentration for the given date.  This data set contains 20 columns of data: Date, Source, Site ID, POC, Daily Max 1-hour NO<sub>2</sub> concentration, Units, Daily AQI Value, Site Name, Site Name (number), Percent Complete, Aqs Parameter Code, AQS Parameter DESC, CBSA Code, CBSA Name, State Code, State,County Code, County, Site Latitude, and Site Longitude.  There are 2,012 rows in this data set 2,011 of them contain observations. This is essentially the same as the other EPA dataset, just that it contains data for 2021 instead of 2020.\n",
    "\n",
    "**Combining Data Sets for Analysis:** For the time being we are not planning on combining the three data sets into a single dataframe. This is because each respective dataset contains data that contains a variable measured over time (Cases for the COVID-19  dataset and NO<ins>2</ins> levels for the EPA datasets) so they are better left in their own seperate dataframes so we can plot their respective trends over time. In addition, the EPA datasets contain daily measurements of NO<ins>2</ins> levels from different locationns within San Diego county, this makes it so that the number of rows within each dataset do not match and make it difficult to  provide a one to one grouping of the dates within the COVID-19 dataset and the dates within the EPA datesets. Going forward with our analysis we are going to be observing the general trends over time for each respective dataset before moving onto a more sophisticated statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nytimes daily covid dataset\n",
    "covid_df = pd.read_csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv')\n",
    "\n",
    "# EPA 2020 NO2 dataset\n",
    "epa2020_df = pd.read_csv('https://raw.githubusercontent.com/asherbav/covid_pollution_files/main/epa2020.csv')\n",
    "\n",
    "# EPA 2021 NO2 dataset \n",
    "epa2021_df = pd.read_csv('https://raw.githubusercontent.com/asherbav/covid_pollution_files/main/epa2021.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### COVID-19 Dataset Cleaning\n",
    "The first thing that we want to do is take a look at the original datasets to see what they look like. We first take a look at the COVID-19 Dataset entitled: \"COVID-19 Data - US Counties from NYTimes\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to check if there are any null-values that we might want to get rid of  using isnull().sum. We see that there are a bunch of null values inside of the death's columns and the FIPS column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not need either of these columns for our analysis. Our group is tryign to investigate the relationship between COVID-19  cases in San Diego county and the levels of NO<ins>2</ins>  in the atmosphere. This being said, the number of deaths over this period will not be necesssary for our analysis. In addition since our scope is being narrowed to only look at San Diego county, we do  not need the FIPS geographic idnentifiers or the state column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = covid_df.drop(['deaths'], axis = 1)\n",
    "covid_df = covid_df.drop(['fips'], axis = 1)\n",
    "covid_df = covid_df.drop(['state'], axis = 1)\n",
    "covid_df = covid_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will sort the data to only look at San Diego County to narrow our geographical scope, then we can remove the column entirely because we know all the remaining data will be for San Diego county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df_sd = covid_df[covid_df['county'] == 'San Diego']\n",
    "covid_df_sd = covid_df_sd.drop(['county'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are done cleaning the COVID-19 dataset. We run isnull() again to double check that all the NULL/NaN values have been removed from out dataset properly. At  this point this data set is in the state we want to use it for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(covid_df_sd.isnull().sum())\n",
    "print('-----------------') \n",
    "covid_df_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### EPA 2020 Air Quality Data Set Cleaning\n",
    "We will repeat the steps for the COVID dataset from above for the EPA datasets on Air Quality. We display the dataset to get an idea of what it looks like, search for any NULL/NaN values, and then also check the types of all the objects to make sure if everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epa2020_df.isnull().sum())\n",
    "print('-----------------') \n",
    "epa2020_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no null values present, we will not be excluding any rows. \n",
    "\n",
    "There appears to be many columns that we will not be using for our analysis. \n",
    "\n",
    "After looking at each column for their unique values, we noticed that we can safely drop the 'COUNTY', 'COUNTY_CODE','STATE','STATE_CODE','CBSA_NAME','CBSA_CODE','AQS_PARAMETER_DESC','AQS_PARAMETER_CODE','UNITS',and 'Source' columns as there is only a single value representing the entire dataset. \n",
    "\n",
    "The description of the dataset is as follows: The county and its associated code is 'San Diego', the CBSA is 'San Diego-Carlsbad, CA', the air quality parameter we're looking at is 'NO<sub>2</sub>', the unit is in ppb or parts per billion, and the source is 'AQS'. \n",
    "\n",
    "Furthermore the values 'SITE_LATITUDE','SITE_LONGITUDE','Site ID','POC','PERCENT_COMPLETE', and'DAILY_OBS_COUNT' are unnecessary for the analysis that we will be peforming. \n",
    "\n",
    "In short, the columns that we're interested in are the date, the NO2 levels, the AQI, and the particular sites. We will also be renaming multi-word labels. \n",
    "\n",
    "Lastly, we'll need to convert the Date to datetime objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_value_list = ['COUNTY', 'COUNTY_CODE','STATE','STATE_CODE','CBSA_NAME','CBSA_CODE','AQS_PARAMETER_DESC','AQS_PARAMETER_CODE','UNITS','Source']\n",
    "not_used_list = ['SITE_LATITUDE','SITE_LONGITUDE','Site ID','POC','PERCENT_COMPLETE','DAILY_OBS_COUNT']\n",
    "updated_labels = {'Daily Max 1-hour NO2 Concentration': 'NO2', 'DAILY_AQI_VALUE': 'AQI', 'Site Name': 'Site'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that contain only a single value\n",
    "epa2020_df = epa2020_df.drop(same_value_list, axis = 1)\n",
    "\n",
    "# Drop columns that are not going to be used\n",
    "epa2020_df = epa2020_df.drop(not_used_list, axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "epa2020_df = epa2020_df.rename(columns=updated_labels)\n",
    "\n",
    "# Convert date to datetime object\n",
    "epa2020_df['Date'] = pd.to_datetime(epa2020_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2020_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 2021 dataset from the EPA is of a similar format to the 2020 dataset, the same rationale that we used for cleaning the 2020 dataset will be applied. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2021_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(epa2021_df.isnull().sum())\n",
    "print('-----------------') \n",
    "epa2021_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that contain only a single value\n",
    "epa2021_df = epa2021_df.drop(same_value_list, axis = 1)\n",
    "\n",
    "# Drop columns that are not going to be used\n",
    "epa2021_df = epa2021_df.drop(not_used_list, axis = 1)\n",
    "\n",
    "# Rename columns\n",
    "epa2021_df = epa2021_df.rename(columns=updated_labels)\n",
    "\n",
    "# Convert date to datetime object\n",
    "epa2021_df['Date'] = pd.to_datetime(epa2021_df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epa2021_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique values from columns\n",
    " ---\n",
    " County codes all the same\n",
    "\n",
    " County all the same\n",
    "\n",
    " State all the same\n",
    "\n",
    " CBSA name all the same\n",
    "\n",
    " CBSA code all the same\n",
    "\n",
    " AQS_PARAMETER_DESC all the same\n",
    "\n",
    " AQS_PARAMETER_CODE all the same\n",
    " \n",
    "\n",
    " UNITS all the same in ppb(part per billion)\n",
    "\n",
    " Source all the same in AQS\n",
    "\n",
    " PERCENT_COMPLETE = [ 92., 100.,  83.,  88.,  75.,  79.,  96.]\n",
    "\n",
    " Site name = ['Chula Vista', 'Alpine', 'Camp Pendleton', 'Donovan',\n",
    "       'Kearny Villa Rd.', 'San Diego -Rancho Carmel Drive',\n",
    "       'El Cajon - Lexington Elementary School',\n",
    "       'San Diego - Sherman Elementary School']\n",
    "\n",
    " DAILY_OBS_COUNT = [22, 24, 20, 21, 18, 19, 23]\n",
    "\n",
    " DAILY AQI VALUE = [17, 33, 34, 29, 38, 35, 28, 24, 30, 26, 21, 27, 36, 31, 25, 32, 15,\n",
    "        23, 40, 16, 13, 39,  8, 22, 11, 12, 18,  7, 19, 20, 10, 14,  6,  4,\n",
    "        9,  3,  5,  2, 41, 37, 42,  1, 53, 43, 55, 44, 45, 46, 47, 52, 48,\n",
    "       49, 51, 50]\n",
    "\n",
    " Daily Max 1-hour NO2 Concentration = [18, 35, 36, 31, 40, 37, 30, 25, 32, 28, 22, 29, 38, 33, 26, 34, 16,\n",
    "        24, 42, 17, 14, 41, 27,  8, 23, 12, 13, 19,  7, 20, 21, 11, 15,  9,\n",
    "        6,  4, 10,  3,  5,  2, 43, 39, 45, 44,  1, 56, 46, 58, 47, 48, 49,\n",
    "        50, 55, 51, 52, 54, 53]\n",
    "\n",
    " POC = [1, 2]\n",
    "\n",
    " Site ID = [60730001, 60731006, 60731008, 60731014, 60731016, 60731017, 60731022, 60731026]\n",
    " \n",
    " Dates range from 1/01/2020 to 12/31/2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
